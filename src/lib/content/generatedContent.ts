// Auto-generated content imports - do not edit manually
// Generated by scripts/generateContentImports.ts
// This file provides type-safe access to all blog content at build time

import type { SerializedPost } from '@/types/post'

import css_fix_social_icon_flicker_on_theme_toggle_md_content from '@/content/blog/css/fix-social-icon-flicker-on-theme-toggle.md?raw'
import inkdrop_how_i_learn_new_framework_md_content from '@/content/blog/inkdrop/how-i-learn-new-framework.md?raw'
import inkdrop_notes_in_service_of_doing_choosing_inkdrop_md_content from '@/content/blog/inkdrop/notes-in-service-of-doing-choosing-inkdrop.md?raw'
import neovim_native_lsp_setup_in_neovim_0_11__on_macos_md_content from '@/content/blog/neovim/native-lsp-setup-in-neovim-0.11+-on-macos.md?raw'
import tools_build_time_content_generation_how_i_process_blog_posts_at_compile_time_md_content from '@/content/blog/tools/build-time-content-generation-how-i-process-blog-posts-at-compile-time.md?raw'
import typescript_learning_typescript_through_constraint_not_tutorials_md_content from '@/content/blog/typescript/learning-typescript-through-constraint-not-tutorials.md?raw'
import wezterm_wezterm_terminal_setup_md_content from '@/content/blog/wezterm/wezterm-terminal-setup.md?raw'

// Raw markdown content accessible by file path
export const contentModules = {
  '@/content/blog/css/fix-social-icon-flicker-on-theme-toggle.md': css_fix_social_icon_flicker_on_theme_toggle_md_content,
  '@/content/blog/inkdrop/how-i-learn-new-framework.md': inkdrop_how_i_learn_new_framework_md_content,
  '@/content/blog/inkdrop/notes-in-service-of-doing-choosing-inkdrop.md': inkdrop_notes_in_service_of_doing_choosing_inkdrop_md_content,
  '@/content/blog/neovim/native-lsp-setup-in-neovim-0.11+-on-macos.md': neovim_native_lsp_setup_in_neovim_0_11__on_macos_md_content,
  '@/content/blog/tools/build-time-content-generation-how-i-process-blog-posts-at-compile-time.md': tools_build_time_content_generation_how_i_process_blog_posts_at_compile_time_md_content,
  '@/content/blog/typescript/learning-typescript-through-constraint-not-tutorials.md': typescript_learning_typescript_through_constraint_not_tutorials_md_content,
  '@/content/blog/wezterm/wezterm-terminal-setup.md': wezterm_wezterm_terminal_setup_md_content
}

// Processed blog posts with metadata and content
// Note: dates are serialized as ISO strings and must be converted to Date objects
export const processedPosts: SerializedPost[] = [
  {
    "title": "Why transition: all Is Risky (CSS Transition Pitfall)",
    "date": "2025-12-04T00:00:00.000Z",
    "description": "It wasn’t catastrophic but once you see it, you can’t unsee it. On slower machines or reduced motion environments, it became even more noticeable.",
    "tags": [
      "css",
      "bugs",
      "debugging",
      "fix"
    ],
    "slug": "fix-social-icon-flicker-on-theme-toggle",
    "topic": "css",
    "content": "\n# The Symptom\n\nWhile working on a dark mode toggle, I noticed something subtle but irritating.\nThe social icons would briefly flash before snapping into their correct color\nwhile the rest of the UI transitioned smoothly. At first glance, it looked like\na hydration issue, a delayed theme state update, or even an SVG rendering problem.\nBut after digging deeper, it turned out to be something much simpler.\n\n## The Root Cause\n\nSurprisingly, the issue wasn’t React, the theme toggle, or Vite. I spent way too\nlong checking React DevTools before I thought to look at the CSS. The culprit was\na single line of CSS:\n\n```css\ntransition: all;\n```\n\nBecause the icons used `filter` for coloring, specifying `transition: all` caused\nthe browser to animate every possible property. During the theme change, some of\nthese properties temporarily passed through invalid or intermediate visual states,\nwhich is exactly what caused the flicker.\n\n## The FIX\n\nThe solution was simple once I understood the problem. Instead of transitioning\nevery property, I limited the transition to exactly what I needed. Updating the\nCSS for the social icons to:\n\n```css\n.socials__icon {\n  /* Transition only filter to prevent unwanted flickers */\n  transition: filter var(--transition-duration-normal);\n  filter: drop-shadow(0 0 0 transparent);\n}\n```\n\nOnce I changed:\n\n```css\ntransition: all;\n```\n\nto:\n\n```css\ntransition: filter;\n```\n\nThe flicker disappeared entirely.\n\nNo JavaScript changes.\nNo theme logic changes.\nJust a scoped transition.\n\n# A Lesson in transition: all\n\n> `transition: all` is convenient — but often dangerous.\n\nThis experience reinforced an easy-to-forget rule. Animating all properties can\ncause unintended visual glitches during state changes, trigger strange\nintermediate render states, and make bugs harder to reason about. Explicitly\ntargeting only the properties that need animation is safer, more predictable, and\nprevents subtle UI regressions.\n\nThis small bug reminded me that some of the most valuable lessons come from tiny,\nalmost invisible issues. It wasn’t about performance, complex architecture, or\nadvanced animations. It was about paying attention to the details. I'd been\ncareless with `transition: all` because it was quick and seemed harmless, but\nthat one line caused a subtle visual glitch that took way too long to track down.\n\n## Key Takeaway\n\nBe intentional with transitions. Target only the properties you need to animate\nand avoid `transition: all` unless you really mean it. This prevents subtle\nvisual glitches and makes your UI more predictable.\n",
    "readingTime": 2
  },
  {
    "title": "How I Learn New Framework",
    "date": "2025-12-22T00:00:00.000Z",
    "description": "As a full time Solutions Consultant and self-taught developer, one of the hardest challenges is keeping pace with the ever-changing world of web development while still grounding myself in the fundamentals.",
    "tags": [
      "learning",
      "productivity",
      "personal growth",
      "developer journey"
    ],
    "slug": "how-i-learn-new-framework",
    "topic": "inkdrop",
    "content": "\n## What Drives Me\n\nEvery time a new framework emerges, it shines like a freshly polished tool in a crowded workshop. Its simplicity, elegance, and promise of quick mastery can easily lure beginners like me. I’ve felt that pull, the temptation to dive in headfirst simply because it looks easy to use.\n\nBut I’ve learned to pause. Instead of chasing novelty for its own sake, I ask myself: What tangible benefits does this bring? Which problems does it truly solve compared to my current workflow? Why choose this path over another? And—most importantly—when does it make sense for the project I’m building?\n\nThis approach turns learning from a superficial sprint into a deliberate, meaningful journey. It’s less about following trends and more about understanding purpose.\n\n## Learning the Patterns\n\nWhen I dive into a new framework, one of the first things I notice is the syntax—the patterns, the way pieces fit together. As a beginner, logic often feels like a foreign language. I’ve learned that it’s okay to feel lost at the start. That confusion, frustrating as it can be, is also the part that makes the journey thrilling: the puzzle of picking up tiny fragments of information and slowly connecting them into something meaningful.\n\nI’ve accepted that there’s no shortcut. When I get stuck, I turn to ChatGPT, asking it to explain things in beginner-friendly ways, often with analogies I can relate to. I don’t shy away from the “dumb” questions: What is a React hook? Why do some YouTubers use Zustand? Can I skip React hooks and jump straight to Zustand?\n\nSure, my questions reveal my confusion—but over days, the pieces start to click. I begin to see why Zustand is not a replacement but an essential tool, and why Zustand becomes valuable when managing complex state, like comments and reactions on my blog. Simple tasks like theming still suit useState, but when coordination grows tricky, a tool like Zustand turns chaos into clarity. Slowly, I begin to understand what “complicated” really means in the context of code—and why learning the basics matters before chasing the next shiny tool.\n\n## We Humans Are Not Perfect\n\nAnother crucial part of my learning journey is embracing imperfection. I’ve learned that it’s not enough to simply jot down solutions—I need to capture the confusion, the “why” behind each step, and the thoughts that swirl around my head as I try to make sense of it all.\n\nThis is where [Inkdrop](https://www.inkdrop.app/) comes in. It’s a note-taking app that doesn’t distract me, doesn’t pull me away from the flow of learning. Instead, it gives me focus. It allows me to write freely, to explore my thoughts, and to slowly connect the dots at my own pace. Less friction, more space for curiosity—and more time to truly understand.\n\n## The Journey Matters More Than the Tools\n\nAt the end of the day, it’s not about the newest framework, the slickest library, or the trendiest tool. It’s about the process—the curiosity, the mistakes, the small victories, and the slow, steady understanding that comes from embracing the unknown.\n\nAs a full time Solutions Consultant and self-taught developer, every confusion is a teacher, every “why” is a doorway, and every note I take is a map I can revisit later. The frameworks will change, the syntax will evolve, but the way I learn, reflect, and connect the dots—that is what lasts.\n\nFrameworks change fast. Learning how you learn is the part that compounds.\n",
    "readingTime": 3
  },
  {
    "title": "Notes in Service of Doing: Choosing Inkdrop",
    "date": "2025-12-21T00:00:00.000Z",
    "description": "In this post, I want to share why I chose Inkdrop over tools like Obsidian and Notion—not because they fall short, but because of how I work as a solutions consultant and a part‑time web developer.",
    "tags": [
      "inkdrop",
      "note-taking",
      "developers",
      "productivity",
      "knowledge-management",
      "tools"
    ],
    "slug": "notes-in-service-of-doing-choosing-inkdrop",
    "topic": "inkdrop",
    "content": "\n## What is [Inkdrop](https://www.inkdrop.app/)?\n\nOn the surface, [Inkdrop](https://www.inkdrop.app/) is a note‑taking app for developers. You write in Markdown, you organize your thoughts, and you move on. But for me, it’s more than a notes app—it’s a deliberate constraint, and that’s exactly why it works.\n\n## Simple, Yet Powerful\n\nMost note‑taking apps I’ve tried are incredibly powerful. They come with endless features, deep customization, and thriving plugin ecosystems. Ironically, that power is also their biggest weakness—for me.\n\nWith so many knobs to turn and settings to tweak, I found myself spending more time _designing my note‑taking system_ than actually thinking or working. It became just another rabbit hole, layered on top of my split keyboard obsession and my ever‑evolving Neovim configuration. Another abstraction. Another system to maintain.\n\n[Inkdrop](https://www.inkdrop.app/) isn’t immune to this—you _can_ customize it—but its limits are clearly defined. And that’s what I love about it. The options are intentionally constrained, just enough to get you started quickly and focused on writing. Instead of spending five hours testing hundreds of plugins in search of a “perfect” setup that never really exists, I can sit down and start working through my thoughts.\n\n## When Ideas Become the Product\n\nOne of the most appealing features of modern note‑taking tools is the ability to connect ideas—to visualize them, link them, and grow a so‑called _second brain_. I get the appeal. I genuinely love ideas, and I love seeing how they relate to one another.\n\nBut I’ve also seen how easy it is to get lost in that process.\n\nI’ve watched countless tutorials where the focus shifts from thinking clearly to maintaining an elaborate web of connections. The visual becomes the goal, not the thinking behind it. Over time, the notes stop supporting the work and quietly _become the work_.\n\n## Execution Over Elegance\n\nAs a full‑time solutions consultant and part‑time developer, my job is not to build the most beautiful knowledge system imaginable. My job is to execute. Ideas matter—but they are a means, not the end.\n\nI’ve personally experienced how easy it is to become excellent at organizing notes while struggling to move ideas into reality. Time spent refining note architecture is time not spent designing real systems, solving real problems, or shipping real solutions.\n\nThis isn’t a criticism of Obsidian or Notion. They are fantastic tools, and for many people, they’re the right choice. For me, the deciding factor is cognitive overhead. [Inkdrop](https://www.inkdrop.app/) stays out of my way. It helps me think just enough—and then nudges me back to doing.\n\nAnd right now, that balance is exactly what I need.\n\n## The Community\n\nOne thing that surprised me most about [Inkdrop](https://www.inkdrop.app/) wasn’t the app itself, but the people around it.\n\nCompared to larger tools, the [Inkdrop](https://www.inkdrop.app/) community is small—and to me, that’s a feature, not a limitation. In the [Inkdrop Discord](https://my.inkdrop.app/login?redirect=/discord), the scale is just right: small enough that names feel familiar, conversations carry over from one day to the next, and people don’t disappear into noise.\n\nIt doesn’t feel like standing in a crowded room talking to strangers. It feels like a community.\n\nWhen you ask a question, you’re not shouting into the void. You get thoughtful responses, learn from others workflows, and sometimes just exchange ideas without the pressure to perform or optimize. There’s a sense of connection that’s hard to find in larger ecosystems.\n\nWhat surprised me even more is that while the space is centered around [Inkdrop](https://www.inkdrop.app/), the conversations often go far beyond it. You’ll see discussions about Neovim workflows, React patterns, or how to build [Inkdrop](https://www.inkdrop.app/) plugins—deep, thoughtful responses that are hard to come by in much larger Discord servers, where signal is often drowned out by scale.\n\nIn a space built around thinking clearly and working deliberately, this kind of human‑scale community feels like a natural extension of the tool itself.\n\n## Choosing to Commit\n\n[Inkdrop](https://www.inkdrop.app/) isn’t free. There’s a 30‑day trial—quiet, unhurried, and long enough to tell you whether this tool fits the way you think. By the time the month ends, you don’t need a spreadsheet to decide. You already know.\n\nBut trying [Inkdrop](https://www.inkdrop.app/) isn’t just about testing a product. It’s an invitation to slow the noise, to work with fewer knobs to turn, and to pay attention to what actually matters. If you decide to step in, don’t do it alone—join the conversation. Linger in the community. Ask questions. Listen.\n\nThat’s when the price reveals its real shape. Not as a fee, but as a commitment—to focus over friction, to execution over endless preparation, and to a small, thoughtful space where work gets done quietly and well.\n",
    "readingTime": 4
  },
  {
    "title": "macOS Neovim 0.11+ Native LSP Configuration",
    "date": "2025-12-20T00:00:00.000Z",
    "description": "Step by step guide on how to setup LSP in Neovim 0.11+ in macOS.",
    "tags": [
      "vim",
      "neovim",
      "lsp",
      "configuration"
    ],
    "slug": "native-lsp-setup-in-neovim-0.11+-on-macos",
    "topic": "neovim",
    "content": "\nNeovim 0.11 (released March 2025) introduced a simpler, fully native way to configure the Language Server Protocol (LSP). With this release, LSP becomes a true first-class citizen—no extra plugins required for basic setup.\n\nYou can still use Mason, a Neovim plugin that acts as a portable package manager for external development tooling such as LSP servers, DAP servers, linters, and formatters.\n\n> NOTE: Mason itself does not configure the LSP servers for use in Neovim. It just installs and manages the binaries/tools. To wire them up with Neovim built-in LSP client, you can use mason-lspconfig.nvim together with nvim-lspconfig.\n\nWhat we’ll cover today is a more manual approach. It requires installing LSP servers—such as lua-language-server—directly on your machine. This approach isn’t portable. You’ll need to reinstall the server when setting up a new machine, or automate it with a shell [script](https://github.com/rjleyva/dotfiles-macos/blob/main/scripts/dev-setup.sh).\n\nLet's begin with installing `lua-language-server` via homebrew:\n\n```bash\nbrew install lua-language-server\n```\n\n> NOTE: You can also install this via npm but I prefer to use homebrew for this instance.\n\n### Structure Overview\n\nThe structure is based on [Marco Peluso](https://www.youtube.com/watch?v=tdhxpn1XdjQ) YouTube video.\n\n```bash\nnvim/\n├── init.lua\n├── lsp/\n│   └── lua_ls.lua\n└── lua/\n    └── core/\n        └── lsp.lua\n```\n\n`lsp/` contains server specifications only, while `lua/core/` is responsible for enabling and orchestrating them. This keeps configuration declarative and avoids coupling server definitions to startup logic.\n\n### Step-by-Step Setup\n\nLet’s start by creating the `nvim` directory:\n\n```bash\nmkdir -p ~/.config/nvim\n```\n\nThen move to the `nvim` directory by running this command:\n\n```bash\ncd ~/.config/nvim\n```\n\nCreate the main `init.lua` file:\n\n```bash\nnvim init.lua\n```\n\nand add this configuration:\n\n```lua\nrequire('core.lsp')\n```\n\nNow let's create the `lsp` directory:\n\n```bash\nmkdir lsp\n```\n\nThen move to `lsp` directory by running this command:\n\n```bash\ncd lsp\n```\n\nCreate `lua_ls.lua` by running this command:\n\n```bash\nnvim lua_ls.lua\n```\n\nThen add this to `lua_ls.lua`:\n\n```lua\nlocal M = {}\n\nM.spec = {\n  cmd = {\n    'lua-language-server',\n  },\n\n  filetypes = {\n    'lua',\n  },\n\n  root_markers = {\n    '.git',\n    '.luacheckrc',\n    '.luarc.json',\n    '.luarc.jsonc',\n    '.stylua.toml',\n    'selene.toml',\n    'selene.yml',\n  },\n\n  settings = {\n    Lua = {\n      runtime = {\n        version = 'LuaJIT',\n      },\n      diagnostics = {\n        globals = { 'vim' },\n      },\n      hint = {\n        enable = true,\n        setType = true,\n        paramType = true,\n        -- paramName = 'All',\n        -- semicolon = 'All',\n        -- arrayIndex = 'All',\n        -- moduleName = 'All',\n      },\n      telemetry = {\n        enable = false,\n      },\n      workspace = {\n        checkThirdParty = false,\n        library = {},\n        -- Enable if you want:\n        -- Full API docs and completion for plugin development\n        -- Autocompletion for all vim.api.* functions\n        -- Uncomment the line below to index Neovim’s runtime and plugins:\n        -- library = vim.api.nvim_get_runtime_file(),\n      },\n    },\n  },\n\n  single_file_support = true,\n  autostart = false, -- manually enabled via vim.lsp.enable\n  log_level = vim.lsp.protocol.MessageType.Warning,\n}\n\nM.name = 'lua_ls'\n\nreturn M.spec\n```\n\n> NOTE: These markers define how a project root is detected. This becomes useful once you start managing multiple language servers consistently.\n\nGo back to `nvim` directory by running this command:\n\n```bash\ncd ~/.config/nvim\n```\n\nThen create `lua` and `core` directory:\n\n```bash\nmkdir -p lua/core/\n```\n\nThen move inside `core` directory:\n\n```bash\ncd lua/core/\n```\n\nand create `lsp.lua`:\n\n```bash\nnvim lsp.lua\n```\n\nThen enable it using `vim.lsp.enable` like this:\n\nThis explicitly enables the Lua language server by name:\n\n```lua\nvim.lsp.enable({\n  'lua_ls',\n})\n```\n\n> NOTE: `vim.lsp.enable()` is available starting in Neovim 0.11 and replaces the need for `nvim-lspconfig` in simple setups.\n> This approach works well for most setups, but more complex workflows may still benefit from `lspconfig` or Mason integrations.\n\nInside Neovim you can run:\n\n```\ncheckhealth lsp\n```\n\nand you'll see something like this:\n\n```\nvim.lsp: Active Clients ~\n- lua_ls (id: 1)\n  - Version: 3.15.0\n  - Root directory: ~/dotfiles-macos\n  - Command: { \"lua-language-server\" }\n  - Settings: {\n      Lua = {\n        diagnostics = {\n          globals = { \"vim\" }\n        },\n        hint = {\n          enable = true,\n          paramType = true,\n          setType = true\n        },\n        runtime = {\n          version = \"LuaJIT\"\n        },\n        telemetry = {\n          enable = false\n        },\n        workspace = {\n          checkThirdParty = false,\n          library = {}\n        }\n      }\n    }\n  - Attached buffers: 2, 3\n```\n\nThis output confirms that `lua_ls` is running successfully.\n\nThis setup is what I currently use daily in my Neovim workflow.\n\n### Why use native LSP in Neovim 0.11+?\n\nMy main reason for choosing this approach is simple: fewer plugins to maintain, faster startup times, and easier debugging. While manually configuring LSP takes a bit more effort, it taught me a lot about what’s actually happening behind the scenes. I’m in control of everything, and each configuration exists because I need it—not because a plugin decided for me.\n\n### Who is this for?\n\nThis setup is ideal if you:\n\n- Use Neovim 0.11+\n- Want fewer plugins and more control\n- Prefer understanding how LSP works under the hood\n\nIf you want a fully portable, zero-setup experience, Mason may still be a better fit.\n\nThis approach scales naturally as you add more language servers. In future posts, I’ll cover keymaps, diagnostics, formatting, and multi-server setups—still using Neovim’s native LSP.\n\nYou can find the full working Neovim configuration [here](https://github.com/rjleyva/dotfiles-macos).\n\n### Next steps\n\n- Add more language servers using the same `lsp/` pattern\n- Define LSP keymaps and diagnostics\n- Integrate formatting without external plugins\n\nSee you in the next post.\n",
    "readingTime": 5
  },
  {
    "title": "Build-Time Content Generation: How I Process Blog Posts at Compile Time",
    "date": "2025-12-24T00:00:00.000Z",
    "description": "A deep dive into my custom build-time content processing system that transforms markdown files into type-safe TypeScript modules, including the trade-offs and design decisions.",
    "tags": [
      "build-tools",
      "typescript",
      "markdown",
      "performance",
      "developer-experience",
      "content-management"
    ],
    "slug": "build-time-content-generation-how-i-process-blog-posts-at-compile-time",
    "topic": "tools",
    "content": "\nWhen I started building my personal blog, I wanted something that felt both fast and maintainable. Most static site generators handle content at build time, but I found myself wanting more control over the process. Instead of using a framework's content layer, I built my own build-time content generation system.\n\nIt started simple—a script to read markdown files and generate some TypeScript—but evolved into a sophisticated pipeline that validates content, calculates reading times, and creates type-safe imports. The result is a blog that loads instantly while giving me complete control over how content flows from markdown to the browser.\n\n## The Problem I Was Solving\n\nTraditional static site generators like Next.js or Astro handle content processing automatically. But I wanted:\n\n- **Type safety**: Content should be validated at build time, not runtime\n- **Performance**: No content parsing during page loads\n- **Flexibility**: Full control over how markdown gets transformed\n- **Developer experience**: Clear error messages and validation\n\nMy blog posts live as markdown files with YAML frontmatter:\n\n```yaml\n---\ntitle: 'Build-Time Content Generation'\ndescription: 'A deep dive into my custom build system'\ndate: '2025-12-24'\ntags: ['typescript', 'build-tools']\n---\n```\n\nThe challenge was transforming these files into something my React components could use efficiently.\n\n## The Solution: Build-Time Processing\n\nInstead of parsing markdown at runtime, I created a build script that runs during compilation. Here's how it works:\n\n### File Discovery\n\nThe system recursively scans my content directory, finding all `.md` files:\n\n```typescript\nconst discoverMarkdownFiles = (): string[] => {\n  const discoveredFiles: string[] = []\n\n  const scanDirectoryRecursively = (\n    absoluteDirectoryPath: string,\n    relativePathFromContentRoot = ''\n  ): void => {\n    const directoryEntries = fs.readdirSync(absoluteDirectoryPath, {\n      withFileTypes: true\n    })\n\n    for (const entry of directoryEntries) {\n      const fullEntryPath = path.join(absoluteDirectoryPath, entry.name)\n      const relativeEntryPath = path.join(\n        relativePathFromContentRoot,\n        entry.name\n      )\n\n      if (entry.isDirectory()) {\n        scanDirectoryRecursively(fullEntryPath, relativeEntryPath)\n      } else if (entry.isFile() && entry.name.endsWith('.md')) {\n        discoveredFiles.push(relativeEntryPath)\n      }\n    }\n  }\n\n  scanDirectoryRecursively(BLOG_CONTENT_DIRECTORY)\n  return discoveredFiles\n}\n```\n\nThis creates a flat list of all markdown files, preserving their relative paths.\n\n### Frontmatter Validation\n\nEach file gets parsed for YAML frontmatter with strict validation:\n\n```typescript\nconst validateFrontmatter = (\n  frontmatter: Partial<PostFrontmatter> | null | undefined,\n  filePath: string\n): PostFrontmatter => {\n  if (!frontmatter) {\n    throw new FrontmatterValidationError(\n      'No frontmatter found. Please add YAML frontmatter with required fields (title, date, description)',\n      filePath\n    )\n  }\n\n  if (\n    typeof frontmatter.title !== 'string' ||\n    frontmatter.title.trim() === ''\n  ) {\n    throw new FrontmatterValidationError(\n      'Missing or invalid \"title\" field. Title must be a non-empty string',\n      filePath\n    )\n  }\n\n  // ... date and description validation continues\n}\n```\n\nI built this validation because I wanted to catch content errors during builds, not in production. Every post must have a title, date, and description.\n\n### Content Processing\n\nFor each valid file, the system extracts metadata and processes the content:\n\n```typescript\nconst blogPost = {\n  title: parsedFile.frontmatter.title,\n  date: dateValue.toISOString(), // Serialized for JSON compatibility\n  description: parsedFile.frontmatter.description,\n  tags: parsedFile.frontmatter.tags ?? [],\n  slug: slugFromFilename,\n  topic: topicFromPath, // Extracted from directory structure\n  content: parsedFile.markdownBody,\n  readingTime: estimatedReadingTimeMinutes\n}\n```\n\nThe reading time calculation uses a simple but effective formula:\n\n```typescript\nconst wordCount = parsedFile.markdownBody\n  .split(/\\s+/)\n  .filter(word => word.trim().length > 0).length\n\nconst estimatedReadingTimeMinutes =\n  wordCount === 0 ? 0 : Math.ceil(wordCount / 200) // 200 WPM\n```\n\n### Type-Safe Module Generation\n\nThe most interesting part is how this generates actual TypeScript code:\n\n```typescript\nconst generateContentLoaderModule = (markdownFilePaths: string[]): string => {\n  const importStatements: string[] = []\n  const moduleMappings: string[] = []\n  const processedBlogPosts: SerializedPost[] = []\n\n  for (const relativeFilePath of markdownFilePaths) {\n    const importVariableName =\n      relativeFilePath.replace(/[^a-zA-Z0-9]/g, '_') + '_content'\n\n    const viteImportPath = `@/content/blog/${relativeFilePath}?raw`\n\n    importStatements.push(\n      `import ${importVariableName} from '${viteImportPath}'`\n    )\n\n    moduleMappings.push(\n      `  '@/content/blog/${relativeFilePath}': ${importVariableName}`\n    )\n  }\n\n  // Generate the complete module...\n}\n```\n\nThis creates a file that looks like:\n\n```typescript\n// Auto-generated content imports - do not edit manually\nimport css_fix_social_icon_flicker_md_content from '@/content/blog/css/fix-social-icon-flicker-on-theme-toggle.md?raw'\nimport typescript_learning_typescript_md_content from '@/content/blog/typescript/learning-typescript-through-constraint-not-tutorials.md?raw'\nimport type { SerializedPost } from '@/types/post'\n\nexport const contentModules = {\n  '@/content/blog/css/fix-social-icon-flicker-on-theme-toggle.md':\n    css_fix_social_icon_flicker_md_content,\n  '@/content/blog/typescript/learning-typescript-through-constraint-not-tutorials.md':\n    typescript_learning_typescript_md_content\n}\n\nexport const processedPosts: SerializedPost[] = [\n  {\n    title: 'Fix Social Icon Flicker on Theme Toggle',\n    date: '2025-12-04T00:00:00.000Z',\n    description: 'How I fixed a subtle CSS transition bug...'\n    // ... complete post metadata\n  }\n] as const\n```\n\n### Runtime Usage\n\nAt runtime, the content is immediately available:\n\n```typescript\nimport { processedPosts } from './generatedContent'\n\nconst convertProcessedPosts = (): Post[] => {\n  return processedPosts.map(post => ({\n    ...post,\n    date: new Date(post.date), // Convert back to Date objects\n    tags: [...post.tags]\n  }))\n}\n\nexport const posts: Post[] = convertProcessedPosts()\n```\n\n## Why This Approach?\n\n### The Benefits\n\n**Performance**: Content loads instantly because it's processed at build time. No runtime parsing means faster page loads and better SEO.\n\n**Type Safety**: TypeScript validates content structure during compilation. If I forget a required field, the build fails with a clear error message.\n\n**Developer Experience**: Writing posts feels natural—just create markdown files. The build system handles the rest, with helpful error messages when something goes wrong.\n\n**Flexibility**: I control exactly how content gets transformed. Want to add a new metadata field? Just update the types and validation logic.\n\n**Caching**: Vite's import system means content gets bundled efficiently. No duplicate processing or unnecessary re-renders.\n\n### The Trade-offs\n\n**Build Complexity**: This system adds complexity to the build process. A simple static site generator would handle this automatically.\n\n**No Hot Reload for Content**: Changing a blog post requires a full rebuild. During development, this means waiting for the content generation script to run.\n\n**Maintenance Overhead**: I have to maintain this custom code. If Vite or TypeScript changes how imports work, I need to update my system.\n\n**Learning Curve**: New contributors need to understand this custom system instead of a standard framework approach.\n\n## Alternatives I Considered\n\n**Runtime Processing**: Parse markdown in the browser or server. This would be simpler but slower, especially for large blogs.\n\n**Static Site Generators**: Use Next.js, Astro, or Eleventy. These handle content processing automatically but give less control.\n\n**Headless CMS**: Contentful or Sanity would provide a nice editing experience but add external dependencies and API calls.\n\n**File-Based CMS**: Something like Contentlayer that generates types from content. This would be similar to my approach but more opinionated.\n\n## The Result\n\nMy blog now builds content once and serves it instantly. The system catches content errors during development, provides excellent TypeScript support, and gives me complete control over the content pipeline.\n\nThe trade-off is complexity—I maintain more code than I would with a standard framework. But the performance benefits and developer experience make it worthwhile for my use case.\n\nIf you're building a blog and want maximum control over your content pipeline, this approach might work for you too. Just be prepared to maintain the build tooling alongside your content.\n\nYou can see the complete implementation in my [blog repository](https://github.com/rjleyva/rjleyva-writes). The content generation script runs automatically during builds, transforming markdown into type-safe TypeScript that my React components can import directly.\n\nWhat do you think—would you build something similar for your own blog, or stick with a more conventional approach?\n",
    "readingTime": 6
  },
  {
    "title": "Learning TypeScript Through Constraints, Not Tutorials",
    "date": "2025-12-23T00:00:00.000Z",
    "description": "How I approach learning TypeScript as a JavaScript developer by starting with strict tooling and letting constraints guide my understanding.",
    "tags": [
      "typescript",
      "tooling",
      "learning",
      "developer-experience",
      "personal-growth"
    ],
    "slug": "learning-typescript-through-constraint-not-tutorials",
    "topic": "typescript",
    "content": "\nWhen I decided to learn TypeScript, I didn’t start with a tutorial or a cheat sheet.\nI started by turning on strict mode.\n\nNot because I understood what every option did—but because I wanted the language to push back. I wanted the compiler and my tooling to surface the gaps in my understanding instead of letting them slip quietly into production.\n\nAs someone new to TypeScript but not new to JavaScript, I’ve learned that comfort is rarely a good teacher. Loose configurations let you move fast, but they also let misunderstandings hide. Strict configurations do the opposite—they interrupt you, slow you down, and force you to be explicit.\n\nSo instead of easing into TypeScript, I chose to begin with a strict tsconfig and a conservative ESLint setup. Not to be “correct” from day one, but to create a feedback loop where every warning meant something I didn’t yet understand.\n\nThis meant setting up my tooling in a way that wouldn’t let me “accidentally” write unsafe code. I wanted ESLint and TypeScript to be noisy—especially early on—so every warning became a prompt to learn, not something to ignore.\n\nHere’s an example of how I configure my `eslint.config.js` in a Vite + React + TypeScript blog.\n\n> NOTE: This isn’t a recommendation to copy this config wholesale. The value isn’t in the exact rules — it’s in choosing constraints that make incorrect assumptions impossible to ignore.\n\n```javascript\nimport jsxA11y from 'eslint-plugin-jsx-a11y'\nimport reactPlugin from 'eslint-plugin-react'\nimport reactHooks from 'eslint-plugin-react-hooks'\nimport reactRefresh from 'eslint-plugin-react-refresh'\nimport globals from 'globals'\nimport tseslint from 'typescript-eslint'\n\nexport default [\n  {\n    ignores: ['dist', 'node_modules', 'build', '.vite']\n  },\n  {\n    files: ['**/*.{ts,tsx}'],\n    languageOptions: {\n      ecmaVersion: 'latest',\n      globals: globals.browser,\n      parser: tseslint.parser,\n      parserOptions: {\n        project: ['./tsconfig.app.json', './tsconfig.node.json']\n      }\n    },\n    settings: {\n      react: {\n        version: 'detect'\n      }\n    },\n    plugins: {\n      '@typescript-eslint': tseslint.plugin,\n      react: reactPlugin,\n      'jsx-a11y': jsxA11y,\n      'react-hooks': reactHooks,\n      'react-refresh': reactRefresh\n    },\n    rules: {\n      ...reactPlugin.configs.recommended.rules,\n\n      ...jsxA11y.configs.recommended.rules,\n\n      ...reactHooks.configs.recommended.rules,\n\n      'react/react-in-jsx-scope': 'off',\n      'react/jsx-uses-react': 'off',\n      'react/prop-types': 'off',\n\n      ...tseslint.configs.strictTypeChecked[0].rules,\n      ...tseslint.configs.stylisticTypeChecked[0].rules,\n\n      '@typescript-eslint/prefer-nullish-coalescing': 'error',\n      '@typescript-eslint/prefer-optional-chain': 'error',\n      '@typescript-eslint/no-unnecessary-condition': 'error',\n      '@typescript-eslint/strict-boolean-expressions': 'error',\n      '@typescript-eslint/no-explicit-any': 'error',\n      '@typescript-eslint/no-empty-object-type': 'error',\n\n      '@typescript-eslint/no-unused-vars': [\n        'error',\n        { argsIgnorePattern: '^_', varsIgnorePattern: '^_' }\n      ],\n\n      '@typescript-eslint/explicit-function-return-type': 'error',\n      '@typescript-eslint/explicit-module-boundary-types': 'error',\n\n      'react-refresh/only-export-components': [\n        'error',\n        { allowConstantExport: true }\n      ]\n    }\n  }\n]\n```\n\nThis setup is intentionally strict. Some of these rules slowed me down at first, and that was the point. Each error forced me to ask _why_ TypeScript was unhappy—and that question is where the learning happened.\n\nAfter setting up strict linting, I carried the same philosophy into my TypeScript configuration. Rather than using a single `tsconfig` for everything, I split my setup into two: one for the browser-facing app and one for Node-based tooling.\n\nThe goal wasn’t completeness—it was clarity. Each environment should fail loudly in ways that actually matter to it.\n\nAnd this is how I setup `tsconfig.app.json`\n\n```json\n{\n  \"compilerOptions\": {\n    \"target\": \"ESNext\",\n    \"lib\": [\"ES2024\", \"DOM\", \"DOM.Iterable\"],\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"moduleDetection\": \"force\",\n    \"jsx\": \"react-jsx\",\n    \"useDefineForClassFields\": true,\n    \"noEmit\": true,\n    \"esModuleInterop\": true,\n    \"resolveJsonModule\": true,\n    \"allowImportingTsExtensions\": false,\n    \"isolatedModules\": true,\n    \"verbatimModuleSyntax\": true,\n    \"strict\": true,\n    \"exactOptionalPropertyTypes\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"noImplicitOverride\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"skipLibCheck\": true,\n    \"baseUrl\": \"./\",\n    \"paths\": {\n      \"@/*\": [\"src/*\"]\n    }\n  },\n  \"include\": [\"src\", \"prettier.config.ts\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\nTurning on `strict` was non-negotiable. It ensured that TypeScript would always assume the least about my code unless I proved otherwise.\n\n`exactOptionalPropertyTypes` forced me to be honest about my data models. Optional didn’t mean “sometimes undefined”—it meant _truly optional_.\n\nAnother excellent choice is `noUncheckedIndexedAccess`, Arrays are objects stop feeling \"safe\", this helps me learn defensive access pattern naturally.\n\n`*noPropertyAccessFromIndexSignature` subtly teaches me about structural typing, why loose onjects are dangerous and when to model with records vs interfaces.\n\n`verbatimModuleSyntax + isolatedModules` These options pushed me to write code that behaves the same way at runtime as it does in my head—no hidden transformations, no surprises.\n\nThe way I handle Node `tsconfig.node.json` is strict in the same way but scoped differently.\n\n```json\n{\n  \"compilerOptions\": {\n    \"tsBuildInfoFile\": \"./node_modules/.tmp/tsconfig.node.tsbuildinfo\",\n    \"target\": \"ESNext\",\n    \"lib\": [\"ES2024\"],\n    \"module\": \"ESNext\",\n    \"moduleResolution\": \"bundler\",\n    \"moduleDetection\": \"force\",\n    \"useDefineForClassFields\": true,\n    \"noEmit\": true,\n    \"esModuleInterop\": true,\n    \"resolveJsonModule\": true,\n    \"allowImportingTsExtensions\": false,\n    \"isolatedModules\": true,\n    \"verbatimModuleSyntax\": true,\n    \"strict\": true,\n    \"exactOptionalPropertyTypes\": true,\n    \"noPropertyAccessFromIndexSignature\": true,\n    \"noImplicitOverride\": true,\n    \"noUncheckedIndexedAccess\": true,\n    \"forceConsistentCasingInFileNames\": true,\n    \"noUnusedLocals\": true,\n    \"noUnusedParameters\": true,\n    \"noFallthroughCasesInSwitch\": true,\n    \"skipLibCheck\": true,\n    \"baseUrl\": \"./\",\n    \"paths\": {\n      \"@/*\": [\"src/*\"]\n    }\n  },\n  \"include\": [\"vite.config.ts\", \"vitest.config.ts\", \"scripts/**/*.ts\"],\n  \"exclude\": [\"node_modules\", \"dist\"]\n}\n```\n\nThe Node config mirrors most of the same constraints, but removes anything browser-specific. Keeping them aligned helps me build a consistent mental model while still respecting the environment I’m targeting.\n\nI didn’t understand all of these options upfront. Some of them only made sense _after_ they broke my assumptions. That breakage is what made them valuable.\n\nConstraints are free. The compiler doesn’t care how you learned — only whether your assumptions hold.\n\nI also came across a great extension to learn TypeScript [Total TypeScript](https://www.totaltypescript.com/vscode-extension), I'm still figuring out how use this inside Neovim, but for the time being I installed [VSCode](https://code.visualstudio.com/) to experiment with TypeScript and use it alongside [Pretty TypeScript Errors](https://open-vsx.org/extension/yoavbls/pretty-ts-errors)\n\nHere's how I use it on my own Vite + React + TypeScript [Blog](https://github.com/rjleyva/rjleyva-writes).\n",
    "readingTime": 5
  },
  {
    "title": "My WezTerm Terminal Setup",
    "date": "2025-12-05T00:00:00.000Z",
    "description": "How I tuned my terminal for long, focused coding sessions by reducing visual noise and prioritizing ergonomics.",
    "tags": [
      "wezterm",
      "terminal",
      "productivity",
      "setup"
    ],
    "slug": "wezterm-terminal-setup",
    "topic": "wezterm",
    "content": "\n# Finding Zen in My Terminal\n\nI spend most of my day in the terminal. At first, I didn’t notice the small UI\ndetails that quietly distracted me—tab bars, window chrome, slight background\nclutter. Over time, I realized these little things were adding noise and making\nlong coding sessions more tiring than they needed to be.\n\nThis is the story of how I stripped my terminal down to just what I need,\ncreating a setup that lets me focus for hours without friction.\n\n> This isn’t a “best practices” guide. It’s just what works for me.\n\n## Saying Goodbye to the Tab Bar\n\nOnce I leaned on TMUX for splits and layouts, the tab bar became redundant. I\nturned it off:\n\n```lua\nenable_tab_bar = false\n```\n\nIt was like decluttering my desk. Suddenly, there was nothing in my way but the\ntext.\n\n## Minimal but Practical\n\nI also wanted to keep the window frame minimal but practical. I don’t need full\nwindow chrome, just enough to resize the terminal when I need it:\n\n```lua\nwindow_decorations = \"RESIZE\"\n```\n\n## A Subtle Blur for Separation (macOS)\n\nOn macOS, I added a subtle blur behind the terminal. I experimented with\ntransparency and different blur levels until I landed on something gentle:\n\n```lua\nmacos_window_background_blur = 10\n```\n\nIt gives a slight separation from the desktop without making the text fuzzy—just\nenough breathing room to reduce eye fatigue.\n\n## Full Opacity for Comfort\n\nI used to play with transparency, but in the end, full opacity won. The text\nfeels more consistent and easier on the eyes:\n\n```lua\nwindow_background_opacity = 1.0\n```\n\n## Choosing a Font That Works\n\nFonts are surprisingly important. I went with Lilex Nerd Font because it’s\nreadable and has great glyph coverage. I also bumped the size up—comfort over\ncramming as many lines as possible:\n\n```lua\nfont = wezterm.font_with_fallback({ \"Lilex Nerd Font\" })\nfont_size = 18\n```\n\n## Scrollback That Actually Works\n\nScrollback is another small tweak that makes a big difference. A deeper buffer\nmeans I can review long logs or retrace commands without frustration:\n\n```lua\nscrollback_lines = 10000\n```\n\n## Colors That Don’t Tire Your Eyes\n\nFinally, colors. I use the solarized-osaka palette because it’s easy on the eyes\nfor long sessions. Nothing flashy, nothing harsh:\n\n```lua\ncolors = {\n  foreground = \"#839395\",\n  background = \"#001419\",\n\n  cursor_bg = \"#839395\",\n  cursor_border = \"#839395\",\n  cursor_fg = \"#001419\",\n\n  selection_bg = \"#1a6397\",\n  selection_fg = \"#839395\",\n\n  ansi = {\n    \"#001014\",\n    \"#db302d\",\n    \"#849900\",\n    \"#b28500\",\n    \"#268bd3\",\n    \"#d23681\",\n    \"#29a298\",\n    \"#9eabac\",\n  },\n\n  brights = {\n    \"#001419\",\n    \"#db302d\",\n    \"#849900\",\n    \"#b28500\",\n    \"#268bd3\",\n    \"#d23681\",\n    \"#29a298\",\n    \"#839395\",\n  },\n},\n```\n\n## The Full Zen Configuration\n\n```lua\nlocal wezterm = require(\"wezterm\")\n\nlocal M = {}\n\nM.spec = {\n  enable_tab_bar = false,\n  window_decorations = \"RESIZE\",\n  window_background_opacity = 1.0,\n  macos_window_background_blur = 10,\n  font = wezterm.font_with_fallback({ \"Lilex Nerd Font\" }),\n  font_size = 18,\n  scrollback_lines = 10000,\n\n  colors = {\n    foreground = \"#839395\",\n    background = \"#001419\",\n\n    cursor_bg = \"#839395\",\n    cursor_border = \"#839395\",\n    cursor_fg = \"#001419\",\n\n    selection_bg = \"#1a6397\",\n    selection_fg = \"#839395\",\n\n    ansi = {\n      \"#001014\",\n      \"#db302d\",\n      \"#849900\",\n      \"#b28500\",\n      \"#268bd3\",\n      \"#d23681\",\n      \"#29a298\",\n      \"#9eabac\",\n    },\n\n    brights = {\n      \"#001419\",\n      \"#db302d\",\n      \"#849900\",\n      \"#b28500\",\n      \"#268bd3\",\n      \"#d23681\",\n      \"#29a298\",\n      \"#839395\",\n    },\n  },\n}\n\nreturn M.spec\n```\n\nOver time, I realized that small adjustments—fonts, colors, scrollback, even\nsubtle blur—compound in impact. Each tweak reduces friction, letting the terminal\nfade into the background so I can focus on code.\n\nThis setup is my “zen mode.” It’s not perfect and it will probably evolve, but\nfor now, it transforms the terminal from a tool I wrestle with into a space I can\ninhabit for hours, fully immersed in work.\n",
    "readingTime": 3
  }
] as const
